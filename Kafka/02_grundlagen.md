# Grundlagen
Im Folgenden werden zunächst die Grundlagen von Kafka erläutert, um später aufbauend dazu die Architektur sowie die Organisation zu erklären. 

## Lose Kopplung
Bei Informations- bzw. IT-Systemen handelt es sich um Systeme mit einer fallspezifisch unterschiedlichen, hohen Komplexität (Nissen, Termer & Rennenkampff, 2012, S.26). Die hohe Komplexität ist damit verbunden, dass es sich bei einem solchen System um ein Konstrukt aus mehreren Komponenten bzw. Teilsystemen handelt. Da diese Komponenten in Wechselwirkung zueinander stehen, wirken sich gegebenenfalls sämtliche Aktionen aufeinander aus. Wedde (1973, S. 372) folgert, dass bei der Ergreifung von Korrekturmaßnahmen bei einer Fehlfunktion davon auszugehen ist, dass ungewünschte Systemzustände durch die Wechselwirkungen entstehen können. Demnach stellt eine Problemlösung bei einer Störung eine potenzielle Gefahrenquelle für Fehlerzustände anderer Komponenten innerhalb des Systems dar. Diese Beziehung zwischen einzelnen Teilsystemen, Prozessen oder Komponenten stellt eine Abhängigkeit voneinander dar und kann grundlegend als Form der Datenübertragung aufgefasst werden. Erfolgt zwischen den Teilsystemen beispielsweise eine komplizierte Synchronisation, so entsteht das Problem der geringeren Übersichtlichkeit über die Wirkungsweise des Gesamtsystems, welches die Grundlage für den Ansatz der losen Kopplung darstellt (Wedde, 1973, S. 372 f.).

Das Prinzip der losen Kopplung ist an den Wandel der Architektur von Systemen geknüpft. In der Historie zeichnet sich hierbei ein Weg vom Monolith über eine N-Tier-Architektur bis hin zur aktuellen Architektur der Microservices ab. Ein Monolith umfasst alle Funktionalitäten einer Anwendung, die im Regelfall mit ihren Diensten lediglich intern zur Verfügung stehen (Salah, Zemerly, Yeun, Al-Qutayri & Al-Hammadi, 2016, S. 321-322). Für externe Systeme, Dienste oder beispielsweise Datenbanken stehen keine Schnittstellen zur Verfügung. Wird ein Teil der Gesamtanwendung modifiziert, so sind im Regelfall komplexe (Re-) Deployments mit entsprechenden Tests und Ausfallzeiten bzw. Downtimes erforderlich, da die komplexe Anwendung abhängig von allen Teilen ist.

Eine Aufteilung des Monolithen nach Funktionen erfolgt(e) in der N-Tier-Architektur (Salah et al., 2016, S. 319), in welcher Systeme beispielsweise als Web-, Datenbank-, File- oder Applikationsserver klassifiziert werden. Wird ein Teil der Gesamtanwendung verändert, so sind nur Änderungen an einem Teil der Komponenten, im Idealfall nur an einer Komponente erforderlich, ohne die anderen Komponenten einzuschränken oder anpassen zu müssen. Tests und eine entsprechende Downtime sind trotzdessen notwendig und eine Skalierbarkeit der Anwendung ist durch die Architektur nicht gegeben.

Der Einsatz von Microservices bietet dagegen eine deutlich losere Kopplung und bedeutet den Einsatz bezüglich Daten und Verarbeitung abgegrenzter Einheiten (Salah et al., 2016, S. 319). Da Dienste und Funktionalitäten nach außen hin bereitgestellt werden (können), können sie von anderen Microservices oder ggf. von Drittanbietersystemen verwendet werden. Microservices bieten eine deutlich bessere Möglichkeit in Bezug auf Wartbarkeit und Skalierung (Salah et al., 2016, S. 322). Mit der steigenden Anzahl von Microservices stellt sich die Herausforderung, der abnehmenden losen Kopplung entgegenzuwirken. Apache Kafka stellt ein Werkzeug der losen Kopplung dar, welches eine Entkopplung der steigenden Microservice-Anzahl bewirken kann. Dies wird realisiert, indem sich alle Microservices mit Apache Kafka verbinden und Kafka verwenden, sodass die einzelnen Microservices für sich zeitlich, räumlich sowie logisch entkoppelt sind.

## Potenzial für Kafka
Kafka kann für betriebliche Abläufe unterstützend auf Systeme, Teile von Systemen oder Komponenten jeglicher Art wirken, an denen Änderungen nicht oder nur äußerst aufwändig einzeln vorgenommen werden können, ohne (negativ) auf das Gesamtsystem zu wirken (Narkhede et al., 2017, S. 140 f.). Für Änderungen an einem System, welches eine Abhängigkeit für andere Systeme darstellt, kann sich dies in Ausfallzeiten, neu entstehenden Abhängigkeiten oder notwendigen Anpassungen der Software äußern.

Komplementär zu solchen komplexen Abhängigkeiten wurde Kafka entwickelt bzw. realisiert. Kafka orientiert sich dabei am zuvor erläuterten Designprinzip "Lose Kopplung", welches in Bezug auf Kafka die Entkopplung eines Produzenten von einem Konsumenten bedeutet (Narkhede et al., 2017, S. 140 f.). Diese Entkopplung kann zeitlich, räumlich und/oder logisch erfolgen. Die zeitliche Entkopplung hat zur Folge, dass der Produzent nicht auf den Konsumenten bzw. seine Nachricht warten muss und es daher für den Konsumenten nicht von Bedeutung ist, ob, wann und/oder wie von welchem Produzenten die Nachricht verteilt wurde. Die räumliche Entkopplung bedeutet, dass die beiden Komponenten Produzent und Konsument meist physikalisch voneinander getrennt sind. Diese physikalische Trennung kann sich als einfach Trennung von zwei physikalischen Servern bis hin zu mehreren Systemen, die über verschiedene Netzwerke verbunden sind, äußern. Logisch entkoppelt sind Produzent und Konsument, wenn sie sich auf unterschiedlichen Plattformen befinden und/oder unterschiedliche Protokolle nutzen können.

Historisch gewachsen sind laut Shree et al. (2017, S. 4), vor allem in Unternehmen, sogenannte Batch-Jobs, um Daten von Quellsystemen zu lesen, sie zu filtern, zu transformieren sowie zu verarbeiten und auf Zielsystemen bereitzustellen. Handelt es sich um größere Datenmengen bzw. "Big Data", so wird ein sehr zeitaufwändiger Vorgang bei der Verarbeitung von Datenmengen durchlaufen, wodurch Resultate erst nach einer entsprechenden Zeitverzögerung bereitgestellt werden können. Während Batch-Jobs damit keine Verarbeitung von Daten in Echtzeit ermöglichen, kann Apache Kafka laut den Autoren im Bereich des Data Processing die Verarbeitung von Neartime-Daten sowie Realtime-Daten bieten. "Realtime" bedeutet, dass es sich um eine Echtzeitverarbeitung handelt, während "Neartime" eine Verarbeitung mit der Nähe zur Echtzeit darstellt.

## Datenverarbeitung
Eine traditionelle Verfahrensweise bei der Verarbeitung von vorwiegend großen Datenmengen stellen Batch-Jobs dar (Shree et al., 2017, S. 4). Diese Jobs kommen bzw. kamen häufig zum Einsatz, unterliegen jedoch Limitierungen (Narkhede et al., 2017, S. 263). Mit der Verarbeitung durch Batch-Jobs entstehen demnach häufig sehr lange Laufzeiten, was in Bezug auf zeitliche Ressourcen negativ auf Abhängigkeiten zwischen mehreren Jobs wirkt. Weiterhin kann es sehr problematisch sein, wenn ein Fehler in der Verarbeitung ("Data Processing") auftritt und die Folgen für die davon abhängigen Folgeschritte kritisch sind.

Insbesondere mit dem Zugewinn der Bedeutung von "Neartime" und "Realtime" wird bzw. wurde die Verwendung von Batch-Jobs fast unmöglich (Shree et al., 2017, S. 4). Bei Neartime bestehen in der zeitlichen Betrachtung sehr kurze Abstände bis zur Bereitstellung der Daten auf dem Weg von der Quelle zum Ziel (Narkhede et al., 2017, S. 250). Hierbei gilt die Annahme, dass die Originaldaten einer minimal-unbedeutenden oder keiner Änderung unterliegen, bis sie ausgeliefert sind. Handelt es sich um Daten, die zu jeder Zeit den letzten, als auch den aktuellen Zustand darstellen, so spricht man von Echtzeitdaten bzw. "Realtime". Realtime Data wird erforderlich, wenn ein System in der Lage sein soll, in einer minimalen Zeit reagieren zu können. Beispiele für solche Systeme finden sich beispielsweise in der Missbrauchserkennung bei Kreditkarten, Fehleranalysen oder Empfehlungssystemen. Für die aktuelle Zeit gilt, dass es nicht mehr genügt, Daten schlichtweg zu sammeln oder als "Big Data" zu betrachten, sondern dass die Notwendigkeit besteht, Daten schnellstmöglich zur Verfügung zu stellen und damit "Fast Data" bzw. "Realtime Data" zu bedienen.

Viele Geschäfts- und Aufgabenfelder, zu denen unter anderem der Finanzsektor und die Netzwerküberwachung zählen, nutzen "Data Streams" mit verteilten Systemen sehr intensiv, um durchgehend Realtime Data zu beziehen. Le Noac'h, Costan und Bougé (2017, S. 4803) ordnen einer typischen "Stream Processing Pipeline" vier Phasen zu, die in Tabelle 1 aufgeführt sind.

Tabelle 1. *Übersicht gesamter Prozess mit vier Phasen und deren geeigneter Lösungen.*

| Phase             | Beschreibung | Geeignete Lösung(en) |
| ----------------- | ------------ | -------------------- |
| Datenerfassung    | Sammeln von Daten in Echtzeit ("Realtime") | beliebige Datenquelle                   |
| Datenübernahme    | Verteilen des Datenstroms ("Data Stream") auf mehrere Maschinen für die parallele Verarbeitung | Apache Kafka                            |
| Datenverarbeitung | Verarbeitung des Datenstroms auf verteilten Systemen | Apache Flink, Apache Spark, Apache Apex |
| Datenspeicherung  | Persistentes Speichern der Ergebnisse der Zwischendaten für die Fehlertoleranz, Datenarchivierung sowie Nachbearbeitung | REDIS, Apache HDFS, Cassandra           |

Für den gesamten Prozess liegen demnach mindestens vier Phasen vor, die in der Praxis in der Form der für die jeweilige Phase eingesetzten Tools bzw. Lösungen durchlaufen werden. In der Pipeline liegen damit vier mögliche Schritte bzw. Punkte vor, die einen Falschenhals ("bottleneck") darstellen können. In einer exemplarischen Performance-Betrachtung des Tools Apache Flink stellte sich heraus, dass die Wahl und Konfiguration der Lösung für die entsprechende Phase einen maßgeblichen Einfluss haben kann. So verzeichnet Apache Flink einen maximalen Durchsatz von ca. 15 Millionen Events pro Sekunde, wenn es "standalone" ohne Apache Kafka für die Datenübernahme ("Ingestion") betrieben wird, während die Integration von Apache Kafka in den Prozess bewirkt, dass der Durchsatz nur noch etwa drei Millionen Events je Sekunde beträgt (Le Noac'h et al., 2017, S. 4804).

Es wird deutlich, dass Apache Kafka keine Allzwecklösung darstellt, die ohne eine gezielte Betrachtung, Konfiguration und Anpassung an die Anwendungsszenarien und infrastrukturellen Gegebenheiten eingesetzt werden kann oder sollte. In den folgenden Kapiteln wird thematisiert, wie Apache Kafka aufgebaut ist und arbeitet.

---

| [<< Einleitung](01_einleitung.md) | Grundlagen | [Architektur von Apache Kafka >>](03_kafka_architektur.md) |
|-----------------------------------|------------|------------------------------------------------------------|
